{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dario Bertazioli \n",
    "\n",
    "3rd, June 2019\n",
    "\n",
    "\n",
    "# Assignment 4: The Flow Shop Problem\n",
    "\n",
    "The objective of the assignment is to apply different resolution methods to a non linear combinatorial problem. The problem that we will deal with is the Flow shop scheduling problem in which we have n machines and m jobs. Each job must be processed in all the machines following the same order, that is the i-th operation of the job must be executed on the i-th machine.\n",
    "\n",
    "Moreover, we assume that machines can not work on more than one process simultaneously and that for each job the operation time in each machine is different and known at the beginning. You can assume assume that the order in which jobs are processed is exactly the same for all the machines.\n",
    "\n",
    "The objective of the problem is to find an ordering of the jobs that minimizes total job execution time (also called makespan) that corresponds to the time on which all jobs get processed.\n",
    "\n",
    "Your task is to implement one or different local search techniques in order to find a sub-optimal solution on the biggest possible set of instances and compare your results against:\n",
    "\n",
    "* the best known solution values\n",
    "\n",
    "* the results obtained using an algorithm available in R/Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the FlowShop problem, it is necessary to define the target function, which every algorithm that will be applied will try to minimize.\n",
    "\n",
    "In literature, this objective function is well known as \"Makespan\" function, and so it will be called in this work.\n",
    "\n",
    "This function will be the most relevant one, with function calls from every algorithm multiple (actually a lot of) times. Because of this consideration, i decided to implement such a function in a compiled Cython cell, for a better performance.\n",
    "\n",
    "I tested the difference between a normal  python function and a compiled-in-Cython one, and the result is clear: the Cythonic one returns the call in less then $8~ \\mu$s, whereas the Pythonic one takes a time of the order of ~$10$ ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from numpy import zeros\n",
    "cpdef calc_makespan( int [:] perm,int [:,:] times): #,m_seq):\n",
    "    cdef int job_count = len(perm)\n",
    "    cdef int machine_count =len(times[0])\n",
    "    #makespan = [[0] * (machine_count + 1) for _ in range(0, job_count + 1)] \n",
    "    cdef int[:,::1] makespan=zeros((job_count+1,machine_count+1), dtype='int32')\n",
    "    #for i, job in enumerate(perm):\n",
    "    for i in range(job_count):\n",
    "        #makespan[i][0]=0\n",
    "        for machine in range(machine_count):\n",
    "            makespan[i + 1][machine + 1] = max(makespan[i][machine + 1], makespan[i + 1][machine]) + times[perm[i]][machine]#times[job][machine]\n",
    "    \n",
    "    return makespan[job_count][machine_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function basically calculates the total time for execution of all the jobs.\n",
    "\n",
    "In order to do this, it sums, up to an i-th job/j-th machine, the total total time passed until this job (considering the previous jobs on previous machines) and adding the maximum value between the time passed until it finishes processing on the previous machine and the time passed for the other job to finish on the current machine. \n",
    "\n",
    "This procedure is iterated up to the last machine.\n",
    "\n",
    "Consequently, we load the datasets for defining the makespan function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of jobs: 20\n",
      "Please input the number of machines: 5\n",
      "required computations on jobs: 20, machines: 5.0\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "#requiring the particular time matrix to the user\n",
    "no_of_jobs=int(input('Please input the number of jobs: ') or 100) # default value is 20\n",
    "no_of_machines=float(input('Please input the number of machines: ') or 20) # default value is 0.8\n",
    "print(\"required computations on jobs: {}, machines: {}\".format(no_of_jobs, no_of_machines) )\n",
    "\n",
    "if no_of_jobs==20 and no_of_machines==5:\n",
    "    #first of taill. 20x5 matrices, converted in xls for easy/fast parsing\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/20x5_flowshop.xlsx\",\n",
    "                         sheet_name=\"S1\",\n",
    "                         index_col =[0])     upper_b=1278\n",
    "elif no_of_jobs==100 and no_of_machines==20:\n",
    "    #first of taill. 100x20 matrices\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/100x20_flowshop.xlsx\",\n",
    "                         sheet_name=\"S1\",\n",
    "                         index_col =[0]) \n",
    "    upper_b=6286\n",
    "elif no_of_jobs==500 and no_of_machines==20:\n",
    "    #first of taill. 500x20 matrices\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/500x20_flowshop.xlsx\",\n",
    "                         sheet_name=\"S1\",\n",
    "                         index_col =[0]) \n",
    "else:\n",
    "    print(\"unsupported number of jobs or number of machines (not implemented)\")\n",
    "\n",
    "m=df_tmp.T.values #Transposing for personal preference and extracting the correspondent numpy 2D array\n",
    "m=m.astype(\"int32\") #ensuring it to be of type \"int32\", for better computational performance\n",
    "print(m.shape)\n",
    "\n",
    "#m_list=df_tmp.T.values.tolist() #for a easier iteration/slicing, \n",
    "#but slower on makespan access (not cythonizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an idea of the Flow Shop let's take a look to the Gantt Chart of the problem, showing the disposition of the jobs over different machines, considering the white spacing between jobs as idle times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial GAnt Chart](makespan_initial_20x5.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first try, I like to start with the genetic algorithm, having very appreciated it during the explanatory lesson.\n",
    "\n",
    "However, reading the regarding literature, i do not expect it to be particularly fast.\n",
    "I tested it on a 20x5, 100x20 and 500x20 (it becomes quite slow on the last one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from numpy import zeros\n",
    "\n",
    "cpdef calc_makespan( int [:] perm,int [:,:] times): #,m_seq):\n",
    "    cdef int job_count = len(perm)\n",
    "    cdef int machine_count =len(times[0])\n",
    "    #makespan = [[0] * (machine_count + 1) for _ in range(0, job_count + 1)]\n",
    "    cdef int[:,::1] makespan=zeros((job_count+1,machine_count+1), dtype='int32')\n",
    "    #print(makespan)\n",
    "    #for i, job in enumerate(perm):\n",
    "    for i in range(job_count):\n",
    "        #makespan[i][0]=0\n",
    "        for machine in range(machine_count):\n",
    "            makespan[i + 1][machine + 1] = max(makespan[i][machine + 1], makespan[i + 1][machine]) + times[perm[i]][machine]#times[job][machine]\n",
    "    \n",
    "    return makespan[job_count][machine_count]\n",
    "\n",
    "cpdef GA(int [:,:] df, \n",
    "         int population_size=5000, \n",
    "         double crossover_rate=1.,\n",
    "         double mutation_p=0.1,\n",
    "         double mutation_gen_rate=0.2,\n",
    "         int n_iteration=100\n",
    "        ):\n",
    "    \n",
    "    cdef int job_count=len(df)\n",
    "    cdef int n_mutations=round(job_count*mutation_gen_rate)\n",
    "    \n",
    "    #####################\n",
    "    # create population #\n",
    "    #####################\n",
    "    \n",
    "    best_makespan=1000000000\n",
    "    best_list,best_obj=[],[]\n",
    "    population=[]\n",
    "    \n",
    "    for i in range(population_size):\n",
    "        \n",
    "        nxm_random_num=list(np.random.permutation(job_count)) # generate a random permutation\n",
    "        population.append(nxm_random_num) # insert in population\n",
    "\n",
    "    for n in range(n_iteration):\n",
    "        \n",
    "        curr_best_makespan=1000000000           \n",
    "        \n",
    "        #############\n",
    "        # crossover #\n",
    "        #############\n",
    "        \n",
    "        parents=copy.deepcopy(population) #better use deecopy for dereferentiation/\n",
    "        mut_list=copy.deepcopy(population)\n",
    "        rand_seq=list(np.random.permutation(population_size)) # random sequence for the crossover\n",
    "\n",
    "        for m in range(int(population_size/2)):\n",
    "            \n",
    "            crossover_trhs=np.random.rand()\n",
    "            \n",
    "            if crossover_rate>=crossover_trhs:\n",
    "            \n",
    "                p1= population[rand_seq[2*m]][:]\n",
    "                p2= population[rand_seq[2*m+1]][:]\n",
    "                first_child=['na' for i in range(job_count)]\n",
    "                second_child=['na' for i in range(job_count)]\n",
    "                c=round(job_count/2)\n",
    "                swap_ind=list(np.random.choice(job_count, c, replace=False))\n",
    "\n",
    "                for index in range(c):\n",
    "                \n",
    "                    first_child[swap_ind[index]]=p2[swap_ind[index]]\n",
    "                    second_child[swap_ind[index]]=p1[swap_ind[index]]\n",
    "                \n",
    "                c1=[p1[i] for i in range(job_count) if p1[i] not in first_child]\n",
    "                c2=[p2[i] for i in range(job_count) if p2[i] not in second_child]\n",
    "\n",
    "                for i in range(job_count-c):\n",
    "                \n",
    "                    first_child[first_child.index('na')]=c1[i]\n",
    "                    second_child[second_child.index('na')]=c2[i]\n",
    "                \n",
    "                mut_list[rand_seq[2*m]]=first_child[:]\n",
    "                mut_list[rand_seq[2*m+1]]=second_child[:]\n",
    "        \n",
    "        ############\n",
    "        # mutation #\n",
    "        ############\n",
    "        \n",
    "        for m in range(len(mut_list)):\n",
    "            \n",
    "            mut_thrs=np.random.rand()\n",
    "            \n",
    "            if mutation_p >= mut_thrs:\n",
    "                # chooses the mutation pos.\n",
    "                swap_ind=list(np.random.choice(job_count, n_mutations, replace=False)) \n",
    "                tmp_swap=mut_list[m][swap_ind[0]] \n",
    "                \n",
    "                for i in range(n_mutations-1):\n",
    "                    mut_list[m][swap_ind[i]]=mut_list[m][swap_ind[i+1]] #shifting (might be ameliorated)\n",
    "\n",
    "                mut_list[m][swap_ind[n_mutations-1]]=tmp_swap \n",
    "\n",
    "        #######################\n",
    "        # fitness calculation #\n",
    "        #######################\n",
    "        \n",
    "        gene_fin=copy.deepcopy(parents)+copy.deepcopy(mut_list) #parent and mutated\n",
    "        gene_fitness,gene_fit=[],[]\n",
    "        fitness=0\n",
    "        mks=[0 for elem in range(2*population_size)]\n",
    "        \n",
    "        for c in range(2*population_size):\n",
    "            mks[c]=calc_makespan(np.array(gene_fin[c], dtype=\"int32\"),df)\n",
    "            gene_fitness.append(1/mks[c])\n",
    "            gene_fit.append(mks[c])\n",
    "            fitness+=gene_fitness[c]\n",
    "        \n",
    "        #########################\n",
    "        # individuals selection #\n",
    "        #########################\n",
    "        \n",
    "        ind_fit_list,cum_fit_list=[],[]\n",
    "\n",
    "        for i in range(population_size*2):\n",
    "            ind_fit_list.append(gene_fitness[i]/fitness)\n",
    "        for i in range(population_size*2):\n",
    "            cum_sum=0\n",
    "            for j in range(0,i+1):\n",
    "                cum_sum=cum_sum+ind_fit_list[j]\n",
    "            cum_fit_list.append(cum_sum)\n",
    "\n",
    "        rand_sel=[np.random.rand() for i in range(population_size)]\n",
    "\n",
    "        for i in range(population_size):\n",
    "            if rand_sel[i]<=cum_fit_list[0]:\n",
    "                population[i]=copy.deepcopy(gene_fin[0])\n",
    "                break\n",
    "            else:\n",
    "                for j in range(0,population_size*2-1):\n",
    "                    if rand_sel[i]>cum_fit_list[j] and rand_sel[i]<=cum_fit_list[j+1]:\n",
    "                        population[i]=copy.deepcopy(gene_fin[j+1])\n",
    "        \n",
    "        ##########################\n",
    "        # updating best makespan #\n",
    "        ##########################\n",
    "        \n",
    "        for i in range(population_size*2):\n",
    "            if gene_fit[i]<curr_best_makespan:\n",
    "                curr_best_makespan=gene_fit[i]\n",
    "                now_perm=copy.deepcopy(gene_fin[i])\n",
    "\n",
    "        if curr_best_makespan<=best_makespan:\n",
    "            best_makespan=curr_best_makespan\n",
    "            best_perm=copy.deepcopy(now_perm)\n",
    "    \n",
    "    \n",
    "    print(\"best permutation\",best_perm)\n",
    "    print(\"best makespan:%f\"%best_makespan)\n",
    "    return best_perm,best_makespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with the 20x5 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best permutation [14, 8, 18, 5, 13, 2, 1, 0, 6, 7, 15, 3, 4, 17, 11, 16, 10, 12, 9, 19]\n",
      "best makespan:1306.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([14, 8, 18, 5, 13, 2, 1, 0, 6, 7, 15, 3, 4, 17, 11, 16, 10, 12, 9, 19], 1306)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA(m, n_iteration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best permutation [0, 7, 16, 1, 5, 15, 8, 12, 13, 3, 2, 14, 18, 11, 4, 17, 10, 9, 6, 19]\n",
      "best makespan:1322.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 7, 16, 1, 5, 15, 8, 12, 13, 3, 2, 14, 18, 11, 4, 17, 10, 9, 6, 19], 1322)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA(m, n_iteration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we anticipated, the performances seems not to be so great.\n",
    "\n",
    "After reading some literature, I tried some parameters tuning (as indicated e.g. in \"Khan, Bazul & Govindan, Kannan & Jeyapaul, R. (2010 IJAOM).\n",
    "\n",
    "However, the results did not change so much, so that after comparing with the python library \"pyeasyga\", whose algorithm results were similar to those obtained previously, i tried out other algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyeasyga import pyeasyga\n",
    "\n",
    "# setup seed data\n",
    "data=list(range(no_of_jobs))\n",
    "\n",
    "# initialise the GA\n",
    "ga = pyeasyga.GeneticAlgorithm(seq.tolist(),\n",
    "                            population_size=200,\n",
    "                            generations=100,\n",
    "                            crossover_probability=0.8,\n",
    "                            mutation_probability=0.1,\n",
    "                            elitism=True,\n",
    "                            maximise_fitness=True)\n",
    "\n",
    "# define and set function to create a candidate solution representation\n",
    "def create_individual(data):\n",
    "    individual = data[:]\n",
    "    random.shuffle(individual)\n",
    "    return individual\n",
    "\n",
    "ga.create_individual = create_individual\n",
    "\n",
    "# define and set the GA's crossover operation\n",
    "def crossover(parent_1, parent_2):\n",
    "    crossover_index = random.randrange(1, len(parent_1))\n",
    "    child_1a = parent_1[:crossover_index]\n",
    "    child_1b = [i for i in parent_2 if i not in child_1a]\n",
    "    child_1 = child_1a + child_1b\n",
    "\n",
    "    child_2a = parent_2[crossover_index:]\n",
    "    child_2b = [i for i in parent_1 if i not in child_2a]\n",
    "    child_2 = child_2a + child_2b\n",
    "    \n",
    "    return child_1, child_2\n",
    "\n",
    "ga.crossover_function = crossover\n",
    "\n",
    "# define and set the GA's mutation operation\n",
    "def mutate(individual):\n",
    "    mutate_index1 = random.randrange(len(individual))\n",
    "    mutate_index2 = random.randrange(len(individual))\n",
    "    individual[mutate_index1], individual[mutate_index2] = individual[mutate_index2], individual[mutate_index1]\n",
    "\n",
    "ga.mutate_function = mutate\n",
    "\n",
    "# define and set the GA's selection operation\n",
    "def selection(population):\n",
    "    #print(population)\n",
    "    \n",
    "    return random.choice(population)\n",
    "\n",
    "ga.selection_function = selection\n",
    "\n",
    "# define a fitness function\n",
    "def fitness (individual, data):\n",
    "    fitness=0\n",
    "    v=calc_makespan(np.array(individual, dtype=\"int32\"), m)\n",
    "    fitness+= 1/v\n",
    "    return fitness\n",
    "ga.fitness_function = fitness       # set the GA's fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga.run()                            # run the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297, [16, 14, 2, 18, 12, 10, 13, 15, 0, 17, 8, 5, 6, 1, 3, 4, 7, 11, 9, 19])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit, sel_perm = ga.best_individual()\n",
    "calc_makespan(np.array(sel_perm, dtype=\"int32\"), m), sel_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is not an horrible result, but it can be explained by the few iterations done (not having some great computational power), and probably by the not-optimal choice of the algorithm parameters  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing (SA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm I would like to implement is the simulated annealing algorithm.\n",
    "\n",
    "The basic idea is to allow exploration of different configurations in order to find a candidate to the optimal sequence. \n",
    "\n",
    "The initial temperature, a parameter controlling the possibility to explore different configurations (higher T means higher probability to explore states characterized by higher \"energy\", in this case higher makespan total time), is slowly decreased to allow the convergence to a good final sequence, hopefully characterized by a low value of the makespan function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly let us implement the *swap move function*, which will allow the exploration of the landscape of possible sequence configuration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapJobs (seq_init,n_swap=2, copy=True):#, verbose=False):\n",
    "    if copy:\n",
    "        seq=np.copy(seq_init)\n",
    "    else:\n",
    "        seq=seq_init #usefull for the library annealer (being a void function basically)\n",
    "        \n",
    "    index1=random.randint(0,len(seq)-1, size=n_swap)\n",
    "    index2=random.randint(0,len(seq)-1, size=n_swap)\n",
    "    \n",
    "    #if verbose: #commenting for fasting up\n",
    "    #    print(\"index: \",index1, \"  \",index2)\n",
    "    for i in range(n_swap):\n",
    "        seq[[index1[i], index2[i]]] = seq[[index2[i], index1[i]]]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def SimAnn(seq_init, m, tmax=5, tmin=0.01, alpha=0.9999, t_ini=10, n_swap=2, maxIterNoChange=200, scale_t=True, n_iterations=1000):\n",
    "    \n",
    "    seq=np.copy(seq_init)\n",
    "    Temp = t_ini\n",
    "    \n",
    "    best_mks = calc_makespan(seq, m)\n",
    "    now_mks=best_mks\n",
    "    iterNoChange = 0\n",
    "    maxit = n_iterations\n",
    "    n_it = 0\n",
    "    \n",
    "    while(Temp >= tmin and n_it <= maxit):\n",
    "        iterNoChange += 1\n",
    "        n_it += 1\n",
    "        new_seq = swapJobs(seq, n_swap = n_swap)\n",
    "        curr_mks = calc_makespan(new_seq, m)\n",
    "    \n",
    "        if curr_mks <= best_mks:    \n",
    "            seq = np.copy(new_seq)\n",
    "            now_mks = curr_mks\n",
    "            best_mks = now_mks\n",
    "            iterNoChange = 0\n",
    "            \n",
    "        elif exp((now_mks-curr_mks)/Temp) > np.random.uniform(0, 1, 1):\n",
    "            now_mks = curr_mks\n",
    "            seq = np.copy(new_seq)\n",
    "            iterNoChange = 0\n",
    "          \n",
    "        Temp = Temp*alpha   #linear decrease of temperature, \n",
    "                            #I also tried exp and log but did not notice great differences\n",
    "\n",
    "        if iterNoChange >= maxIterNoChange:\n",
    "            print(\"Reached max number of iteration without improvement( {}) after {} iterations\".format(iterNoChange, n_it))\n",
    "            break\n",
    "          \n",
    "    if(Temp<=tmin):\n",
    "        print(\"Reached temperature low limit in {} iterations\".format(n_it))\n",
    "    \n",
    "    print(\"exiting Temp \", temp)\n",
    "    return seq, best_mks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the algorithm on the 20x5 matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of iteration without improvment( 500) after 27310 iterations\n",
      "3.2572603099406447\n",
      "CPU times: user 704 ms, sys: 7.83 ms, total: 712 ms\n",
      "Wall time: 708 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8, 16, 14,  7,  2,  5, 10, 12, 13,  1,  0,  4,  6, 18,  3, 17, 15,\n",
       "         9, 19, 11], dtype=int32), 1278)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seq_init=np.array(range(no_of_jobs), dtype=\"int32\") #fixed init\n",
    "seq_init=np.array(list(np.random.permutation(no_of_jobs)), dtype=\"int32\") #random seed permutation\n",
    "%time SimAnn(seq_init, m, n_iterations=100000000, maxIterNoChange=500, t_ini=50,tmin=0.0001, n_swap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to perform quite well, obtaining a candidate for a low-makespan state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SA library:  simanneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try: \n",
    "    import simanneal\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install simanneal --user  # from pypi\n",
    "    import simanneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simanneal import Annealer\n",
    "\n",
    "class FlowShopProb(Annealer):\n",
    "    \"\"\"Test annealer with a FlowShopProb.\"\"\"\n",
    "    def move(self):\n",
    "        \"\"\"perform a swap\"\"\"\n",
    "        swapJobs(self.state, n_swap=3, copy=False)\n",
    "        \n",
    "    def energy(self):\n",
    "        \"\"\"Calculates the length of the route.\"\"\"\n",
    "        return calc_makespan(self.state, self.mks_matrix)\n",
    "    def __init__(self, state, matrix):\n",
    "        self.mks_matrix = matrix\n",
    "        super(FlowShopProb, self).__init__(state) # important!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "     0.01000       1278.00     0.60%     0.00%     0:00:03     0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 24 ms, total: 2.68 s\n",
      "Wall time: 2.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8, 14,  5, 13,  2, 16,  0,  4, 10,  6,  1,  7, 12, 18,  3, 17, 15,\n",
       "         9, 19, 11], dtype=int32), 1278)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow = FlowShopProb(seq, m)\n",
    "flow.steps = 100000\n",
    "flow.copy_strategy = \"deepcopy\"\n",
    "flow.Tmin=0.01\n",
    "\n",
    "%time state, e = flow.anneal()\n",
    "\n",
    "state, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library algorithm converges at the same result. \n",
    "\n",
    "However, it is a bit slower than my implementation.\n",
    "\n",
    "This is reasonable, even because in the doc it is clearly stated that such a module does not aim to great performance, being entirely written in Python, but it aims to give a practical tool for a fast initial exploration of the solution landscape in a optimization problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEH Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the NEH Heuristic, following the method explained in literature (e.g. Kalczynski,  Kamburowski, Omega 35 (2007) 53–60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random #faster for rng tuples\n",
    "from random import randint  #faster for one shot rng\n",
    "\n",
    "from numpy import zeros\n",
    "\n",
    "cpdef calc_makespan( int [:] perm,int [:,:] times): #,m_seq):\n",
    "    cdef int job_count = len(perm)\n",
    "    cdef int machine_count =len(times[0])\n",
    "    #makespan = [[0] * (machine_count + 1) for _ in range(0, job_count + 1)]\n",
    "    cdef int[:,::1] makespan=zeros((job_count+1,machine_count+1), dtype='int32')\n",
    "    #print(makespan)\n",
    "    #for i, job in enumerate(perm):\n",
    "    for i in range(job_count):\n",
    "        #makespan[i][0]=0\n",
    "        for machine in range(machine_count):\n",
    "            makespan[i + 1][machine + 1] = max(makespan[i][machine + 1], makespan[i + 1][machine]) + times[perm[i]][machine]#times[job][machine]\n",
    "    \n",
    "    return makespan[job_count][machine_count]\n",
    "\n",
    "\n",
    "cpdef NEH(int [:,:] m, verbose=False):\n",
    "    \n",
    "    sum_jobs=np.sum(m, axis=1)\n",
    "    n_jobs=m.shape[0]\n",
    "    \n",
    "    sorted_init_perm = np.lexsort((np.array(range(n_jobs)),-sum_jobs)) # Sort by sum_jobs, then index in  start_seq\n",
    "    sorted_init_perm_i = sorted_init_perm[:2] # init permutation sorted \n",
    "    n_positions= len(sorted_init_perm_i) #actually =2\n",
    "    \n",
    "    mk1=calc_makespan(sorted_init_perm_i.astype(\"int32\"), m)#try the makespan in the init seq\n",
    "    \n",
    "    rev_sorted_init_perm_i=sorted_init_perm_i[::-1] #not really working in cython\n",
    "    mk2=calc_makespan(rev_sorted_init_perm_i.astype(\"int32\"), m)#try it in the reversed one\n",
    "\n",
    "    if mk1 <= mk2 :   #save initial best_makespan and starting sequence\n",
    "        best_makespan=mk1\n",
    "        best_seq_init=sorted_init_perm_i\n",
    "    \n",
    "    else: \n",
    "        best_makespan=mk2\n",
    "        best_seq_init=rev_sorted_init_perm_i\n",
    "\n",
    "    n_positions=3 #starting points for the insert of NEH algorithm\n",
    "\n",
    "    curr_perm=best_seq_init\n",
    "    for new_job in sorted_init_perm[2:]:\n",
    "        #print(i)\n",
    "        best_makespan=9999999\n",
    "        \n",
    "        for position in range(n_positions):\n",
    "            temp_perm=np.insert(curr_perm, position, new_job)\n",
    "            temp_mks=calc_makespan(temp_perm.astype(\"int32\"), m)\n",
    "            \n",
    "            if temp_mks < best_makespan:\n",
    "                best_makespan=temp_mks\n",
    "                best_seq=temp_perm\n",
    "    \n",
    "        curr_perm=best_seq        \n",
    "        n_positions+=1\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"best seq: \", best_seq)\n",
    "        print(\"best mks: \", best_makespan)\n",
    "\n",
    "    return best_seq.astype(\"int32\"), best_makespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 16,  8,  7, 14, 13, 10, 15, 12, 18,  5,  3,  4, 17,  0,  1,  9,\n",
       "         6, 19, 11], dtype=int32), 1286)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEH_seq, mks=NEH(m)\n",
    "NEH_seq,mks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It produces a good permutation, with the correspondent makespan corresponding to the upper bound indicated for such a matrix\n",
    "\n",
    "Typically, such a permutation is taken as a starting point for another algorithm, to increase its performances.\n",
    "\n",
    "Therefore, I implemented another algorithm, called Iterated Local Search. But let us first test the NEH resulting sequence on the Simulated Annealing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached temperature limit in 8513 iterations\n",
      "0.0009999338538073665\n",
      "CPU times: user 240 ms, sys: 31 µs, total: 240 ms\n",
      "Wall time: 237 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8,  2, 10, 14, 16,  5,  1, 12,  3, 18, 13,  4,  0, 17,  6,  7, 15,\n",
       "         9, 19, 11], dtype=int32), 1278)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time SimAnn(NEH_seq, m, n_iterations=100000, alpha=0.999,maxIterNoChange=1000, t_ini=5,tmin=0.001, n_swap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, exploiting the good starting point (thus choosing a much lower initial temperature not to allow the system to explore too far from of our initial solution, we reach the same results as before with a reduced number of iterations. \n",
    "\n",
    "The fact we obtained the same value of the candidate min makespan for such a matrix might be a hint of a pretty good solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated Local Search\n",
    "\n",
    "It consists in Iterating the local search heuristic procedure after perturbing the resulting sequence at each step, in such a way to check for more possibilities and better explore the phase space. \n",
    "\n",
    "In the implementation I followed references like the following:  \"Applying Iterated Local Search to the Permutation Flow Shop Problem (Stutzle et al.)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perturb function apply a perturbation on a sequence, by swapping n-pairs of adjacent numbers and j-pairs of distant numbers.\n",
    "\n",
    "(The max dist (interval) parameter is taken from the reference :\"Local search methods for the flowshop scheduling problem with flowtime minimization (Quan Ke Pan, Rubén Ruiz)\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(seq, n_swaps=2, n_changes=1):#, verbose=False):\n",
    "    ###n_swaps: number of pair swaps\n",
    "    ###n_changes: number of long range swaps (let's say in range ~30) cfr.#ADDCIT\n",
    "\n",
    "    #short range swaps\n",
    "    index=random.randint(0,len(seq)-1, size=n_swaps+n_changes)\n",
    "    \n",
    "    #if verbose:\n",
    "    #    print(\"index: \",index)\n",
    "    \n",
    "    for i in range(n_swaps):\n",
    "        seq[[index[i], index[i]+1]] = seq[[index[i]+1, index[i]]]\n",
    "        \n",
    "        #if verbose:\n",
    "        #    print(\"swapping {}-th elem on the right\".format(index[i]))\n",
    "    \n",
    "    #long range swaps\n",
    "    interval = max(round(len(seq)/5), 30) #max long range swap window\n",
    "                                        #30 is an empirical number suggested in [cit] #ADDCIT \n",
    "    if(n_changes==1):\n",
    "    \n",
    "        if (len(seq) > 60):\n",
    "            delta_index = randint(1, interval-1)\n",
    "        else:\n",
    "            delta_index = randint(1, int(len(seq)/2))\n",
    "        \n",
    "        if index[2]+delta_index<len(seq):\n",
    "                sign=1\n",
    "        else:\n",
    "                sign=-1\n",
    "                \n",
    "        seq[[index[2], index[2]+sign*delta_index]] = seq[[index[2]+sign*delta_index, index[2]]]\n",
    "        #if verbose:\n",
    "        #    print(\"exchanged {} with {}\".format(index[2], index[2]+delta_index))\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        for i in range(n_changes):\n",
    "          \n",
    "            if (len(seq) > 60):\n",
    "                delta_index = randint(1, interval-1)\n",
    "            else:\n",
    "                delta_index = randint(1, int(len(seq)/2))\n",
    "            \n",
    "            if index[i+n_swaps]+delta_index<len(seq):\n",
    "                sign=1\n",
    "            else:\n",
    "                sign=-1\n",
    "                \n",
    "            seq[[index[i+n_swaps], index[i+n_swaps]+sign*delta_index]] = seq[[index[i+n_swaps]+sign*delta_index, index[i+n_swaps]]]\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LocalSearch function performs a local search: given a permutation, the function rearranges the order in a sub-sequential way storing the optimal value obtained during the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocalSearch(perm,m, debug=True):\n",
    "    best_makespan = 999999 #calc_makespan(perm, m)\n",
    "    perm_save=perm\n",
    "    \n",
    "    for i in range(len(perm_save)):\n",
    "        elem=perm[i]\n",
    "        t_perm=np.delete(perm, i)\n",
    "        #if debug: \n",
    "        #    if len(np.unique(t_perm))!=(len(perm)-1): print(\"halp: \",len(np.unique(t_perm))) \n",
    "        \n",
    "        for j in range(len(t_perm)):\n",
    "            curr_perm=np.insert(t_perm, j, elem)\n",
    "            curr_mks=calc_makespan(curr_perm, m)\n",
    "            \n",
    "            #if debug: \n",
    "            #    if len(np.unique(curr_perm))!=len(perm): print(\"halp1: \",len(np.unique(curr_perm))) \n",
    "        \n",
    "            if curr_mks <= best_makespan:\n",
    "                best_makespan=curr_mks\n",
    "                best_perm=curr_perm\n",
    "        \n",
    "        perm=best_perm\n",
    "        \n",
    "    return best_perm, best_makespan#, calc_makespan(best_perm, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the ILS procedure we start from a sequence, perform the local search, then in a loop we perturb the obtained sequence and re-perform the local search, always keeping the best result from such a process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IteratedLocalSearch(perm, m, maxIterations=10000, maxIterNoChange=2000, verbose=False):#, break_if_no_changes= False):\n",
    "    \n",
    "    best_perm, best_makespan=LocalSearch(perm, m)\n",
    "    now_perm=np.copy(best_perm)\n",
    "    \n",
    "    count=0\n",
    "    count_no_change=0\n",
    "    \n",
    "    while count < maxIterations:\n",
    "        curr_perm, curr_mks = LocalSearch(perturb(now_perm), m)\n",
    "    \n",
    "        if curr_mks <= best_makespan:\n",
    "            best_makespan = curr_mks\n",
    "            best_perm = np.copy(curr_perm)\n",
    "            now_perm = np.copy(curr_perm)\n",
    "            count_no_change = 0\n",
    "    \n",
    "        count+=1\n",
    "        count_no_change += 1\n",
    "        \n",
    "        if count_no_change == maxIterNoChange:\n",
    "            print(\"no more changes in optimum val\")\n",
    "            print(\"n_it : \", count)\n",
    "            break\n",
    "        \n",
    "    return best_perm, best_makespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm seems to performing pretty well. Indeed, for the 20x5 matrix, given a sequence corresponding (just as an example) to the range of the jobs, it produces the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more changes in optimum val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8, 14,  5, 13, 16,  7, 10, 12,  2, 15,  0,  4,  6, 17, 18,  3,  1,\n",
       "         9, 19, 11], dtype=int32), 1278)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newseq= np.array(list(range(no_of_jobs)), dtype=\"int32\")\n",
    "IteratedLocalSearch(newseq, m, verbose=True,maxIterations=10000, maxIterNoChange=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing an optimal value with 2000 iterations.\n",
    "However, starting from the result of the NEH algorithm, the performance can be improved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more changes in optimum val\n",
      "CPU times: user 3.3 s, sys: 5 µs, total: 3.3 s\n",
      "Wall time: 3.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8, 14, 16,  7,  2,  0, 18, 13,  5,  6, 10,  4,  3,  1, 12, 17, 15,\n",
       "         9, 19, 11], dtype=int32), 1278)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time IteratedLocalSearch(seq, m, verbose=True,maxIterations=200, maxIterNoChange=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reaching the optimal values in 200 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look to the Gantt representation of the optimal solution that we found, comparing such a chart with the previous. It can be noticed a better disposition minimizing idle times.\n",
    "\n",
    "![Gantt chart](makespan_initial_20x5.png \"Gantt chart of the initial configuration\") ![Gantt chart](makespan_final_20x5.png \"Gantt chart of the final configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher rank matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of the implemented algorithm on the other matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 jobs and 20 machines \n",
    "\n",
    "the considered matrix is as usual the first in the related page on Taillard website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of jobs: 100\n",
      "Please input the number of machines: 20\n",
      "required computations on jobs: 100, machines: 20.0\n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "#requiring the particular time matrix to the user\n",
    "no_of_jobs=int(input('Please input the number of jobs: ') or 100) # default value is 20\n",
    "no_of_machines=float(input('Please input the number of machines: ') or 20) # default value is 0.8\n",
    "print(\"required computations on jobs: {}, machines: {}\".format(no_of_jobs, no_of_machines) )\n",
    "\n",
    "if no_of_jobs==20 and no_of_machines==5:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/20x5_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 20x5 matrices\n",
    "    upper_b=1278\n",
    "elif no_of_jobs==100 and no_of_machines==20:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/100x20_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 100x20 matrices\n",
    "    upper_b=6286\n",
    "elif no_of_jobs==500 and no_of_machines==20:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/500x20_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 500x20 matrices\n",
    "else:\n",
    "    print(\"unsupported number of jobs or number of machines (not implemented)\")\n",
    "\n",
    "#print(pt_tmp.head())\n",
    "m1=df_tmp.T.values #Transposing for personal preference and extracting the correspondent numpy 2D array\n",
    "m1=m1.astype(\"int32\") #ensuring it to be of type \"int32\", for better computational performance\n",
    "print(m1.shape)\n",
    "\n",
    "#m_list=df_tmp.T.values.tolist() #for a better iteration\n",
    "#print(m_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEH solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time seq1, mks1=NEH(m1)\n",
    "seq1,mks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.05663378937321"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound_100x20=6286\n",
    "\n",
    "(mks1-upper_bound_100x20)*100/upper_bound_100x20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NEH solution is 4% far from the upper-bound.\n",
    "\n",
    "Trying to improve the performance with the iterated local search, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more changes in optimum val\n",
      "n_it :  500\n",
      "CPU times: user 8min 13s, sys: 24 ms, total: 8min 13s\n",
      "Wall time: 8min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([21, 53, 46, 73, 10, 50, 76, 30, 39, 23, 89, 82, 54, 49, 77, 64, 32,\n",
       "        38, 79, 58, 99, 29, 15, 90, 26,  9, 19, 45, 11, 20,  2, 43, 13, 27,\n",
       "        92, 31, 98, 60,  0,  8, 62,  1, 33, 36, 95, 66, 94, 65, 69, 55,  3,\n",
       "         7, 14,  6, 34, 85, 80, 44,  5, 18, 52, 84, 24, 22, 59, 81, 87, 16,\n",
       "         4, 75, 71, 97, 78, 47, 83, 70, 88, 72, 91, 63, 28, 67, 56, 86, 61,\n",
       "        42, 57, 74, 17, 35, 93, 25, 51, 96, 41, 48, 37, 68, 40, 12],\n",
       "       dtype=int32), 6516)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IteratedLocalSearch(seq1, m1, verbose=True,maxIterations=300, maxIterNoChange=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.658924594336621"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(6516-upper_bound_100x20)*100/upper_bound_100x20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ILS solution is 3.7% far from the upper-bound "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not far from the indicated upper bound. However, I could reach a pretty better sequence just my adding more iterations, with the counterpart of a greater computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SA on 100x20\n",
    "\n",
    "Again, starting from the NEH resulting sequence, we try to optimize the makespan via SA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of iteration without improvment( 100000) after 597766 iterations\n",
      "0.3524215188550217\n",
      "CPU times: user 58.8 s, sys: 1.25 ms, total: 58.8 s\n",
      "Wall time: 58.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([21, 53, 54, 10, 73, 78, 30, 81, 32, 89, 82, 23, 49, 77, 64, 76, 46,\n",
       "        58, 72, 99, 39, 15, 69, 92, 38,  9, 19,  4, 20, 11, 80, 75, 43,  1,\n",
       "        36, 29, 47, 26, 98, 18, 85, 17, 34, 60, 31, 95, 33,  8, 44, 55,  3,\n",
       "        65,  6, 79, 56, 14, 45, 90, 59,  5, 27, 50,  2, 62,  7, 52, 22, 74,\n",
       "        16,  0, 71, 87, 84, 97, 66, 70, 91, 88, 93, 83, 13, 63, 94, 28, 25,\n",
       "        86, 24, 67, 42, 57, 61, 51, 96, 41, 48, 68, 37, 40, 12, 35],\n",
       "       dtype=int32), 6496)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time SimAnn(seq1, m1, n_iterations=1000000, alpha=0.999995,maxIterNoChange=100000, t_ini=7,tmin=0.001, n_swap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.34075723830735"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound_100x20=6286\n",
    "\n",
    "(6496-upper_bound_100x20)*100/upper_bound_100x20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the NEH sequence, my algorithm converges to a state characterized by makespan= 6497, differing of 3.34% from the upper-bound solution.\n",
    "\n",
    "Considering that the solution could be improved with more iterations (and more swaps, probably, in addition to much more computational power) the performance is actually satisfying, because the algorithm lowers the makespan best value significantly after some iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 500 jobs and 20 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of jobs: 500\n",
      "Please input the number of machines: 20\n",
      "required computations on jobs: 500, machines: 20.0\n",
      "(500, 20)\n"
     ]
    }
   ],
   "source": [
    "#requiring the particular time matrix to the user\n",
    "no_of_jobs=int(input('Please input the number of jobs: ') or 100) # default value is 20\n",
    "no_of_machines=float(input('Please input the number of machines: ') or 20) # default value is 0.8\n",
    "print(\"required computations on jobs: {}, machines: {}\".format(no_of_jobs, no_of_machines) )\n",
    "\n",
    "if no_of_jobs==20 and no_of_machines==5:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/20x5_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 20x5 matrices\n",
    "    upper_b=1278\n",
    "elif no_of_jobs==100 and no_of_machines==20:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/100x20_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 100x20 matrices\n",
    "    upper_b=6286\n",
    "elif no_of_jobs==500 and no_of_machines==20:\n",
    "    df_tmp=pd.read_excel(\"/home/dario/Desktop/DecisionModel/Assignment_4/500x20_flowshop.xlsx\",sheet_name=\"S1\",index_col =[0]) #first of taill. 500x20 matrices\n",
    "else:\n",
    "    print(\"unsupported number of jobs or number of machines (not implemented)\")\n",
    "\n",
    "#print(pt_tmp.head())\n",
    "m2=df_tmp.T.values #Transposing for personal preference and extracting the correspondent numpy 2D array\n",
    "m2=m2.astype(\"int32\") #ensuring it to be of type \"int32\", for better computational performance\n",
    "print(m2.shape)\n",
    "\n",
    "#m_list=df_tmp.T.values.tolist() #for a better iteration\n",
    "#print(m_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEH solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 3.08 ms, total: 34.5 s\n",
      "Wall time: 34.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([144, 451, 127, 287, 111, 294, 495, 406,  78, 430, 324, 272, 215,\n",
       "        260, 158,  57, 368,  87, 474, 134, 180,  53, 275, 227,  90, 475,\n",
       "        188,  15, 267,  42, 340,  52,  60, 109,  82, 337, 154, 410, 416,\n",
       "        346, 191, 123, 449, 237, 450, 407, 292, 320, 339, 113,  44, 306,\n",
       "        107, 323, 255, 378, 207, 224,  48, 305, 217, 397,  98, 162, 458,\n",
       "        460,  18, 468, 281, 286, 327, 496, 143,   9, 353, 269,  89, 371,\n",
       "        441, 233, 285, 119, 422, 322, 301, 192, 137, 424, 379,  67, 278,\n",
       "         20,  21, 226, 326, 328, 100, 110, 349, 230, 244, 343, 334, 279,\n",
       "        484,  38, 471, 225, 411, 216, 213, 126, 108, 241, 376, 498, 189,\n",
       "        439, 122,  75, 288, 395, 152, 480, 303, 384, 448, 256,  77, 239,\n",
       "        295, 138, 336, 473, 103, 297, 262, 387, 481,  63,   2,   3, 363,\n",
       "        380, 273, 211,  46,  37,  86, 469, 208,   1, 431, 146,  22,  95,\n",
       "        298, 235, 220, 102, 218, 313, 142, 497, 240, 247, 457, 203,  51,\n",
       "         16,   4, 392, 263, 489, 231, 197,  55, 155, 156,   6, 409,  96,\n",
       "        145, 101,  47,  56, 182, 258,  40, 434, 486, 223, 369, 245, 375,\n",
       "        479, 212, 163, 164, 360, 332, 161, 181, 186, 426,  58, 408, 185,\n",
       "        184, 243, 200, 120, 436, 166, 168, 234,  34, 385, 478, 284, 393,\n",
       "         36, 276, 242, 487, 209, 206,  24, 221, 413, 492, 420, 370, 173,\n",
       "        302, 493, 391, 165,  85, 442,  43, 253, 377, 361, 418,  33, 172,\n",
       "        160, 459, 325, 251, 198,  88, 175, 390,  30,  73, 383,  35, 104,\n",
       "          5, 149, 187,  45, 147, 432, 400, 491,  97, 417, 293, 257, 352,\n",
       "        357, 106, 274, 321, 151, 382, 125, 483,   0, 205, 310, 183, 373,\n",
       "        271,  23, 199, 445,  68,  80, 477, 354, 219, 466, 456, 440,  10,\n",
       "        196, 309, 485, 171, 296, 131, 414, 345, 401, 249, 438, 463, 140,\n",
       "         50, 350, 148,  49, 499,  99, 428, 300, 194, 128, 270, 476, 366,\n",
       "         76, 415, 282,  29,  79, 482, 264, 289, 403, 259, 135, 490, 176,\n",
       "        362,  92, 178, 252, 129, 374, 341, 177, 132, 124,  59,  41,  27,\n",
       "        312, 425,  91, 105, 112,  11, 437, 201, 141, 333, 453, 465, 419,\n",
       "        202,  65,  28, 179, 318, 351,   7, 364,  17, 372, 214, 472, 229,\n",
       "        402, 389, 464, 342, 331,  39, 355, 317, 115, 447, 319, 210,  64,\n",
       "        347,  72, 204, 405, 277, 335, 338, 433, 246, 116, 461,  61, 344,\n",
       "        454, 435, 470,  26, 159, 291, 133, 167, 195, 396, 398, 404, 283,\n",
       "        254, 150, 136, 307, 121, 348, 315,  81, 232, 228, 494, 443, 266,\n",
       "        153, 394, 265, 280, 250, 304, 174, 367, 311,   8, 330, 356, 170,\n",
       "        423, 329,  19,  25, 114, 248, 488,  84, 452,  62,  14, 316, 386,\n",
       "        290,  13, 455, 365,  83,  70,  74, 444, 314, 381, 308, 412, 358,\n",
       "        169, 139,  12, 130, 446, 118, 193, 261, 117, 190,  94, 359, 429,\n",
       "        236, 388, 467,  66, 462, 427, 157, 238,  71, 268,  93, 399,  31,\n",
       "         69, 222,  54, 421,  32, 299], dtype=int32), 26670)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time seq2, mks2=NEH(m2)\n",
    "seq2,mks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8366489747603953"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound_500x100=26189\n",
    "#upper_bound_500x100=26040\n",
    "\n",
    "(mks2-upper_bound_500x100)/upper_bound_500x100*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NEH solution is 1.84% far from the upper-bound indicated in Taillard's benchmarks\n",
    "\n",
    "Trying to improve the performance with the iterated local search, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([346, 294, 406, 301, 324, 226, 430,  87, 260, 281, 474,   9, 267,\n",
       "        109, 134, 340, 497,  53, 410, 127, 123, 450,  82, 191,  60, 287,\n",
       "        337,  90, 275, 320, 395, 292, 215,  57, 162, 306, 339, 368, 107,\n",
       "        207, 224, 180, 286,  52, 397, 217, 327,  98,  18, 496,  44, 269,\n",
       "        475, 233, 119, 438, 322, 371,   0, 113, 323, 192, 154, 143, 144,\n",
       "        441, 471, 495, 326, 349,  21,  89,  67, 498,  20, 422,  78, 343,\n",
       "        230, 272, 241, 448, 328,  77,  75,  42, 279, 288, 103, 110, 216,\n",
       "         38, 213, 225, 152, 295, 100, 262,  46, 387, 297, 239, 484, 158,\n",
       "        244, 481, 189, 256, 242, 465, 235,  22,   1, 218, 208, 431, 102,\n",
       "        458, 138, 108, 303, 380, 126, 384, 273,   2, 411, 278, 363, 392,\n",
       "        220, 439, 336, 211,  37, 457, 473, 424, 379, 489, 460, 449, 353,\n",
       "         55,  16, 263,   3, 188, 285,  48,   4,   6,  47,  96, 122,  15,\n",
       "         95, 313, 155, 240, 298, 486, 156, 146, 245, 231, 184, 255, 182,\n",
       "         58, 142, 480,  40, 468, 203, 166, 149, 163, 332, 479, 376, 408,\n",
       "         34, 212, 181, 200, 120, 436, 161, 247, 360, 173, 206,  17,  86,\n",
       "        391,  51,  43, 426, 409,  85, 418, 469, 375, 223, 284, 393, 370,\n",
       "        487,  97, 237, 243,  33, 325, 321, 407, 377, 209,  35, 234, 442,\n",
       "        104, 478, 172,  56, 334, 258, 187, 491, 382, 183, 302,   5, 400,\n",
       "        199, 171, 137, 493, 434,  23, 249, 459, 477, 390, 483, 361, 197,\n",
       "        276, 385, 345, 253, 312,  80, 305, 205, 257, 310, 383, 271, 196,\n",
       "        186, 221, 101, 466, 194, 428, 309, 140, 413, 251, 456,  24, 445,\n",
       "        112,  76, 357, 492,  49, 369,  36, 440, 175, 476, 164, 354, 499,\n",
       "        415,  10, 403,  45, 485,  73, 300, 296, 185, 125, 165, 160,  79,\n",
       "        463, 366, 432, 148, 259, 270, 135,  99, 145, 219, 252, 124, 176,\n",
       "        372, 420, 490, 128,  30, 177,  59, 141, 437, 333,  11, 419, 105,\n",
       "        401, 201, 214, 350,  92,  50, 132, 330, 374, 389, 282, 179, 293,\n",
       "        277, 178, 414, 355, 364, 425, 318,  64,  41, 453, 464, 229,  39,\n",
       "         68, 106, 472, 317, 331, 319, 342, 202, 198, 115, 335, 246, 264,\n",
       "         91, 291, 344, 338, 435, 362, 204, 133,  28,  72, 396, 470, 159,\n",
       "        454, 129, 433, 447, 195, 404, 416, 405, 398, 210, 461, 136, 451,\n",
       "         61, 121, 307, 153, 131, 274, 394, 378,  81, 347, 168, 311, 315,\n",
       "        283, 417, 150, 232, 250, 341, 443,  65, 254, 423,  19,  25,   8,\n",
       "        329, 304, 248, 316, 488,  27, 356,  63, 373,  62,  84, 351, 147,\n",
       "         14, 266, 151, 365,  70, 114,  13,  83, 455,  74, 381, 314, 290,\n",
       "        265, 174, 358, 308, 352, 228, 169, 446, 130, 444,  26, 193, 494,\n",
       "        452, 139, 118, 170, 412, 190,  94, 261, 386, 117, 367, 289, 482,\n",
       "        111, 429,  12,   7, 359,  29, 280, 227, 467,  66,  88, 236,  31,\n",
       "        388, 462, 348, 427, 238, 116, 157,  71, 268, 399,  69, 402, 167,\n",
       "         93, 222,  54, 421,  32, 299], dtype=int32), 26552)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IteratedLocalSearch(seq2, m2, verbose=True,maxIterations=10, maxIterNoChange=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3860781244033755"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound_500x100=26189\n",
    "#upper_bound_500x100=26040\n",
    "\n",
    "(26552-upper_bound_500x100)/upper_bound_500x100*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to quite limited computational resources, i could perform only 10 cycles of the ILS. \n",
    "\n",
    "However, after those iterations the gap between the upper bound reduced up to 1.39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SA on 500x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of iteration without improvment( 1000000) after 1000000 iterations\n",
      "0.00022698829904838723\n",
      "CPU times: user 10min 13s, sys: 60.2 ms, total: 10min 13s\n",
      "Wall time: 10min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26670"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time s, mks500= SimAnn(seq2, m2, n_iterations=10000000, alpha=0.99999,maxIterNoChange=1000000, t_ini=5,tmin=0.0001, n_swap=10)\n",
    "\n",
    "mks500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "     0.01000      27042.00     0.03%     0.00%     0:08:12     0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 12s, sys: 138 ms, total: 8min 12s\n",
      "Wall time: 8min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([144, 451, 127, 287, 111, 294, 495, 406,  78, 430, 324, 272, 215,\n",
       "        260, 158,  57, 368,  87, 474, 134, 180,  53, 275, 227,  90, 475,\n",
       "        188,  15, 267,  42, 340,  52,  60, 109,  82, 337, 154, 410, 416,\n",
       "        346, 191, 123, 449, 237, 450, 407, 292, 320, 339, 113,  44, 306,\n",
       "        107, 323, 255, 378, 207, 224,  48, 305, 217, 397,  98, 162, 458,\n",
       "        460,  18, 468, 281, 286, 327, 496, 143,   9, 353, 269,  89, 371,\n",
       "        441, 233, 285, 119, 422, 322, 301, 192, 137, 424, 379,  67, 278,\n",
       "         20,  21, 226, 326, 328, 100, 110, 349, 230, 244, 343, 334, 279,\n",
       "        484,  38, 471, 225, 411, 216, 213, 126, 108, 241, 376, 498, 189,\n",
       "        439, 122,  75, 288, 395, 152, 480, 303, 384, 448, 256,  77, 239,\n",
       "        295, 138, 336, 473, 103, 297, 262, 387, 481,  63,   2,   3, 363,\n",
       "        380, 273, 211,  46,  37,  86, 469, 208,   1, 431, 146,  22,  95,\n",
       "        298, 235, 220, 102, 218, 313, 142, 497, 240, 247, 457, 203,  51,\n",
       "         16,   4, 392, 263, 489, 231, 197,  55, 155, 156,   6, 409,  96,\n",
       "        145, 101,  47,  56, 182, 258,  40, 434, 486, 223, 369, 245, 375,\n",
       "        479, 212, 163, 164, 360, 332, 161, 181, 186, 426,  58, 408, 185,\n",
       "        184, 243, 200, 120, 436, 166, 168, 234,  34, 385, 478, 284, 393,\n",
       "         36, 276, 242, 487, 209, 206,  24, 221, 413, 492, 420, 370, 173,\n",
       "        302, 493, 391, 165,  85, 442,  43, 253, 377, 361, 418,  33, 172,\n",
       "        160, 459, 325, 251, 198,  88, 175, 390,  30,  73, 383,  35, 104,\n",
       "          5, 149, 187,  45, 147, 432, 400, 491,  97, 417, 293, 257, 352,\n",
       "        357, 106, 274, 321, 151, 382, 125, 483,   0, 205, 310, 183, 373,\n",
       "        271,  23, 199, 445,  68,  80, 477, 354, 219, 466, 456, 440,  10,\n",
       "        196, 309, 485, 171, 296, 131, 414, 345, 401, 249, 438, 463, 140,\n",
       "         50, 350, 148,  49, 499,  99, 428, 300, 194, 128, 270, 476, 366,\n",
       "         76, 415, 282,  29,  79, 482, 264, 289, 403, 259, 135, 490, 176,\n",
       "        362,  92, 178, 252, 129, 374, 341, 177, 132, 124,  59,  41,  27,\n",
       "        312, 425,  91, 105, 112,  11, 437, 201, 141, 333, 453, 465, 419,\n",
       "        202,  65,  28, 179, 318, 351,   7, 364,  17, 372, 214, 472, 229,\n",
       "        402, 389, 464, 342, 331,  39, 355, 317, 115, 447, 319, 210,  64,\n",
       "        347,  72, 204, 405, 277, 335, 338, 433, 246, 116, 461,  61, 344,\n",
       "        454, 435, 470,  26, 159, 291, 133, 167, 195, 396, 398, 404, 283,\n",
       "        254, 150, 136, 307, 121, 348, 315,  81, 232, 228, 494, 443, 266,\n",
       "        153, 394, 265, 280, 250, 304, 174, 367, 311,   8, 330, 356, 170,\n",
       "        423, 329,  19,  25, 114, 248, 488,  84, 452,  62,  14, 316, 386,\n",
       "        290,  13, 455, 365,  83,  70,  74, 444, 314, 381, 308, 412, 358,\n",
       "        169, 139,  12, 130, 446, 118, 193, 261, 117, 190,  94, 359, 429,\n",
       "        236, 388, 467,  66, 462, 427, 157, 238,  71, 268,  93, 399,  31,\n",
       "         69, 222,  54, 421,  32, 299], dtype=int32), 26670)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow = FlowShopProb(seq2, m2)\n",
    "flow.copy_strategy = \"deepcopy\"\n",
    "\n",
    "#trying the auto strategy for having a better comparison with my implementation, considering comparable CPU time \n",
    "auto_schedule = flow.auto(minutes=10)  \n",
    "flow.set_schedule(auto_schedule)\n",
    "%time state, e = flow.anneal()\n",
    "\n",
    "state, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SA algorithm does not perform in such a situation of great number of jobs. It does not find any sequence better than the initial one, obtained with the NEH. \n",
    "\n",
    "One could increase the number of swap, and possibly the number of iteration, in order to gain better performances. However, this will require much more computational time.\n",
    "\n",
    "However, the comparison with the library algorithm does not show any sign of improvement for this last attempt.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "The most performing algorithm seems to be the Annealing, if tested on a matrix up to 100x20. \n",
    "\n",
    "On the other side, the ILS seems a very stable process, giving a result constantly better than the NEH point of initialization.\n",
    "\n",
    "This initialization with the NEH resulting sequence seems to be very profitable in terms of general performances.\n",
    "\n",
    "The GA algorithm does not seem to perform well. It is particularly slow even on the 20x5 matrix we tested, and further tests on higher rank matrices would lead to huge CPU time requirements.\n",
    "\n",
    "\n",
    "In general, further improving in performance can be obtained by executing more iterations.\n",
    "\n",
    "The problem is that doing so would require a lot of CPU time, running this Pythonic/Cythonic implementation of the algorithm.\n",
    "\n",
    "In order to reduce the required time, one should actually write the same algorithm down in a much lower level language, such as C/C++ or even better Fortran. \n",
    "\n",
    "I tried myself an approach by compiling some basic function (makespan and permutations) with Ft2py, however, mainly due to the lack of available (real!) time, i was not able to integrate the basic data structure within a numpy array (the most C-like looking structures in Py, at least up to my knowledge). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
